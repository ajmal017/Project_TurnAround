{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Domain YG에서 만든 코드를 전체 파일에 적용 시킨다. 각각의 DataFrame에 저장시킨뒤 비교\n",
    "#### 딕셔너리를 이용하여 가중치를 합치는 작업을 거친다. Score = sum(tf_rof)/sum(tf) / 이기 때문에 Key값을 word로 주고 value 값을 sum(tf_rof) , sum(tf) 값으로 주면 좋겠다.\n",
    "#### 명사만 추출 했으나 추후에 서술어까지 해야함 .\n",
    "#### 매일매일 등락률 계산을 위해서는 등락률 계산 모듈이 필요함 Sentiment_Dic_Domain file 참고 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import re \n",
    "\n",
    "from konlpy.tag import Komoran\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWeekday(start, end):\n",
    "#start = '20200411' , end = '20200922'\n",
    "    # 평일을 구하기 위한 datetime의 기본적인 변수를 생성해준다. \n",
    "    s_year = int(start[0:4]) # 2020\n",
    "    s_month = int(start[5:6]) # 4\n",
    "    s_day = int(start[6:8]) # 11\n",
    "\n",
    "    e_year = int(end[0:4]) # 2020\n",
    "    e_month = int(end[5:6]) # 9\n",
    "    e_day = int(end[6:8]) # 22 \n",
    "\n",
    "    day_delta = datetime.timedelta(days=1) \n",
    "    start_date = datetime.date(s_year, s_month, s_day)\n",
    "    end_date = datetime.date(e_year, e_month, e_day)\n",
    "    length = (end_date - start_date).days # 시작일 - 끝나는일의 일 수 \n",
    " \n",
    "    # 평일 데이터만 가져오기 위해 위에서 짠 것들을 합쳐준다.\n",
    "    date_weekday = [] # 평일날짜를 넣기위한 리스트 \n",
    "    for i in range(length+1) : # 마지막날을 포함하기 위해 length에 + 1 을 해준다. \n",
    "        date = start_date + i*day_delta # date 는 for 문을 돌며 day_delta로 1일 씩 더해지게 된다. \n",
    "        date_w = date.weekday() # date에 저장된 날짜를 weekday로 본다 0~6의 값을 가진다. \n",
    "        if date_w < 5 : # 조건문을 걸어 0~4 월~금 만 date_weekday 리스트에 추가하도록한다. \n",
    "            date_weekday.append(str(date))\n",
    "            \n",
    "    return date_weekday # 평일만 포함된 date weekday 리스트가 나온다. 이를 이용해 평일 엑셀 데이터만 불러 오도록 한다. \n",
    "\n",
    "\n",
    "# 년/월/일 변수가 / 로 구분 되어있다면 data name 과 맞춰주기 위해 /를 -로 바꿔주는 부분. \n",
    "def replaceSlash(df) :\n",
    "    dates = []\n",
    "    df_date = df.iloc[:,:1]\n",
    "    df_date = df_date.sort_values(by='date',ascending=False)\n",
    "    list1 = df_date.values.tolist()\n",
    "    for i in range(len(df_date)):\n",
    "        tokens = list1[i][0]\n",
    "        token = tokens.split('-')\n",
    "        year = token[0]\n",
    "        month = token[1]\n",
    "        #month = month.replace('0','')\n",
    "        day = token[2]\n",
    "        date = year + '-' + month + '-' + day \n",
    "        dates.append(date)\n",
    "    return dates\n",
    "\n",
    "# 문장내 모든 conma를 제거해주는 함수 \n",
    "def replaceConma(df, start, finish) : # start, finish 열의 인덱스를 지정해 주면된다. \n",
    "    for j in range(start, finish+1):\n",
    "        for i in range(len(df.iloc[:,j])):\n",
    "            df.iloc[:,j][i] = df.iloc[:,j][i].replace(\",\", \"\")\n",
    "    return df\n",
    "# df = replaceAllConma(df, 1, 9) 1열 부터 9열 까지의 모든 데이터의 conma를 삭제.\n",
    "\n",
    "\n",
    "# user dic에 한글자가 있는 경우 이를 삭제해주는 함수 . filename 에는 userdic name 이 들어간다. \n",
    "def delDicOneword(filename) :\n",
    "    with open(f'{filename}.txt', 'r' ) as f :\n",
    "        line = f.readlines()\n",
    "        print(line)\n",
    "\n",
    "    # 개행문자를 포함하여 글자수가 2개 이하인 모든 글자를 삭제. \n",
    "    for i in line :\n",
    "        i.strip()\n",
    "        if len(i) < 3 :\n",
    "            line.remove(i)\n",
    "\n",
    "    with open(f'{filename}.txt', 'w') as f:\n",
    "        for i in line:\n",
    "            f.write(i)\n",
    "\n",
    "# tf score 계산\n",
    "\n",
    "def getTfrofScore(date) :\n",
    "# date = '2020-04-13' \n",
    "\n",
    "    df1 = pd.read_excel(f'./data_news/YG_DATAyg {date}.xlsx')\n",
    "    sentences = [] \n",
    "    list1 = list(set(df1['title'].values.tolist())) # 중복을 제거 한다.\n",
    "    pattern = '[^\\w\\s]'\n",
    "    repl = ''\n",
    "    for i in list1 :\n",
    "        sen = i.split(']')\n",
    "        if len(sen) >= 2 : # 스플릿 했을때 ] 가 있으면 len이 2 가 나오고 없으면 1이 나옴. 그중 문장을 선택하게 조건문을 부여\n",
    "            sen = sen[1]\n",
    "        else :\n",
    "            sen = sen[0]\n",
    "        sen = re.sub(pattern,\" \",sen) # pattern에서 정의한 특수문자 정규표현식 을 제거 \n",
    "        sen = sen.strip() # 양옆의 공백을 제거 \n",
    "\n",
    "        sentences.append(sen)\n",
    "    sentences\n",
    "\n",
    "    komoran_userdic=Komoran(userdic='./userdicCanSur_YG_Sentiment.txt')\n",
    "    corpus = sentences\n",
    "    wordCount = {}\n",
    "    wordlist = []\n",
    "    answer = []\n",
    "    for i in corpus:\n",
    "        wordlist.append(komoran_userdic.nouns(i))\n",
    "    for i in wordlist:\n",
    "        answer += i\n",
    "    #print(answer)\n",
    "\n",
    "\n",
    "    # 빈도수가 2번 이상인 단어만을 대상으로 한다. \n",
    "\n",
    "    attention = {}\n",
    "    attention = Counter(answer)\n",
    "    df1 = pd.DataFrame(attention.keys())\n",
    "    df1.columns =['Name']\n",
    "    df1['Frequency'] = pd.DataFrame(attention.values())\n",
    "    df1 = df1[df1['Frequency'] >= 2] \n",
    "    df1.reset_index(inplace = True)\n",
    "    df1 = df1.drop('index', axis =1)\n",
    "\n",
    "    # 한글자인 데이터를 삭제 해준다.\n",
    "    for i in range(len(df1)):\n",
    "        word = df1['Name'][i] # iloc로 하면 df를 drop 했을때 키를 못찾는 에러가 발생함. \n",
    "        print(i, word)\n",
    "        if len(word) < 2 : # Name 테이블 안에 글자가 한개이면 이를 삭제\n",
    "            print(i, word)\n",
    "            df1.drop(index=i, inplace=True)\n",
    "\n",
    "\n",
    "    df = df[ df['date'] == date ] # 조건문을 걸어 변수 date 와 같은날의 행의 모든 데이터를 반환 \n",
    "    rof = df['rof'].iloc[0] # 그날의 데이터중 rof값을 반환\n",
    "    \n",
    "    df1['tf_rof'] = df1['Frequency']*rof # 빈도수 dataFrame에 df_rof 값을 저장\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. stock data 를 불러온다 .\n",
    "2. 모든 데이터의 conma를 삭제한다 .\n",
    "3. stock data 의 년월일을 news data 년월일과 맞추기 위해 slash를 삭제하고 hyphen을 넣는다.  \n",
    "##### 미구현 / 등락률을 계산한다. 계산후 na 값은 drop 한다.(가장 첫날에 해당함)\n",
    "4. news data 를 불러온다.\n",
    "##### 서술어 미구현 / 사전 정의된 Komoran 형태소 분석기를 이용해 뉴스 명사(서술어)의 Tf를 계산한다.\n",
    "5. tfrof score를 구하기 위해 stock data에서 new data의 date에 맞는 등락률을 가져와 Tf 에 곱한다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### date weekday 에서 day 리스트를 뽑아서 2020-04-11의 형태로 뽑아 for 문을 돌린다. date 만 넣으면 자동으로 tfrof score를 계산할 수 있도록 구현 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-8007a541f240>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-8007a541f240>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    getWeekday('20200411', '2020922'):\u001b[0m\n\u001b[1;37m                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # csv 파일로 들어가 등락률을 미리 계산해주어야함.  등락률 = 당일대비 / 전일종가\n",
    "    df = pd.read_csv('./data_stock/YG_1y.csv', encoding = 'ISO-8859-1')\n",
    "    df.columns = ['date', 'closing', 'diff', 'volume', 'transaction', 'market', 'high', 'low', 'capital', 'stocks', 'rof']\n",
    "    df = replaceConma(df, 1, 9)\n",
    "    #df = replaceSlash(df) # stock data date가 2020/1/3 일때 사용\n",
    "    \n",
    "    df1 = getTfrofScore('2020-04-11')\n",
    "    days = getWeekday('20200411', '20200922') # 내가 기준으로 한 범위\n",
    "    for day in days\n",
    "        getTfrofScore(day) # 이렇게 for문을 돌리면 각 날짜에 대한 TfrofScore df 를 반환함 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data_news/YG_DATAyg 2020-04-11.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-5f5026176bc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-8e321e556025>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#df = replaceSlash(df) # stock data date가 2020/1/3 일때 사용\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mdf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetTfrofScore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'2020-04-11'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-b0eb3464ddf5>\u001b[0m in \u001b[0;36mgetTfrofScore\u001b[1;34m(date)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;31m# date = '2020-04-13'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[0mdf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'./data_news/YG_DATAyg {date}.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0mlist1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 중복을 제거 한다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         raise ValueError(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, io, engine)\u001b[0m\n\u001b[0;32m    819\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 821\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    822\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    823\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"xlrd\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# a ZIP file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data_news/YG_DATAyg 2020-04-11.xlsx'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\" :\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020-04-13',\n",
       " '2020-04-14',\n",
       " '2020-04-15',\n",
       " '2020-04-16',\n",
       " '2020-04-17',\n",
       " '2020-04-20',\n",
       " '2020-04-21',\n",
       " '2020-04-22',\n",
       " '2020-04-23',\n",
       " '2020-04-24',\n",
       " '2020-04-27',\n",
       " '2020-04-28',\n",
       " '2020-04-29',\n",
       " '2020-04-30',\n",
       " '2020-05-01',\n",
       " '2020-05-04',\n",
       " '2020-05-05',\n",
       " '2020-05-06',\n",
       " '2020-05-07',\n",
       " '2020-05-08',\n",
       " '2020-05-11',\n",
       " '2020-05-12',\n",
       " '2020-05-13',\n",
       " '2020-05-14',\n",
       " '2020-05-15',\n",
       " '2020-05-18',\n",
       " '2020-05-19',\n",
       " '2020-05-20',\n",
       " '2020-05-21',\n",
       " '2020-05-22',\n",
       " '2020-05-25',\n",
       " '2020-05-26',\n",
       " '2020-05-27',\n",
       " '2020-05-28',\n",
       " '2020-05-29',\n",
       " '2020-06-01',\n",
       " '2020-06-02',\n",
       " '2020-06-03',\n",
       " '2020-06-04',\n",
       " '2020-06-05',\n",
       " '2020-06-08',\n",
       " '2020-06-09',\n",
       " '2020-06-10',\n",
       " '2020-06-11',\n",
       " '2020-06-12',\n",
       " '2020-06-15',\n",
       " '2020-06-16',\n",
       " '2020-06-17',\n",
       " '2020-06-18',\n",
       " '2020-06-19',\n",
       " '2020-06-22',\n",
       " '2020-06-23',\n",
       " '2020-06-24',\n",
       " '2020-06-25',\n",
       " '2020-06-26',\n",
       " '2020-06-29',\n",
       " '2020-06-30',\n",
       " '2020-07-01',\n",
       " '2020-07-02',\n",
       " '2020-07-03',\n",
       " '2020-07-06',\n",
       " '2020-07-07',\n",
       " '2020-07-08',\n",
       " '2020-07-09',\n",
       " '2020-07-10',\n",
       " '2020-07-13',\n",
       " '2020-07-14',\n",
       " '2020-07-15',\n",
       " '2020-07-16',\n",
       " '2020-07-17',\n",
       " '2020-07-20',\n",
       " '2020-07-21',\n",
       " '2020-07-22',\n",
       " '2020-07-23',\n",
       " '2020-07-24',\n",
       " '2020-07-27',\n",
       " '2020-07-28',\n",
       " '2020-07-29',\n",
       " '2020-07-30',\n",
       " '2020-07-31',\n",
       " '2020-08-03',\n",
       " '2020-08-04',\n",
       " '2020-08-05',\n",
       " '2020-08-06',\n",
       " '2020-08-07',\n",
       " '2020-08-10',\n",
       " '2020-08-11',\n",
       " '2020-08-12',\n",
       " '2020-08-13',\n",
       " '2020-08-14',\n",
       " '2020-08-17',\n",
       " '2020-08-18',\n",
       " '2020-08-19',\n",
       " '2020-08-20',\n",
       " '2020-08-21',\n",
       " '2020-08-24',\n",
       " '2020-08-25',\n",
       " '2020-08-26',\n",
       " '2020-08-27',\n",
       " '2020-08-28',\n",
       " '2020-08-31',\n",
       " '2020-09-01',\n",
       " '2020-09-02',\n",
       " '2020-09-03',\n",
       " '2020-09-04',\n",
       " '2020-09-07',\n",
       " '2020-09-08',\n",
       " '2020-09-09',\n",
       " '2020-09-10',\n",
       " '2020-09-11',\n",
       " '2020-09-14',\n",
       " '2020-09-15',\n",
       " '2020-09-16',\n",
       " '2020-09-17',\n",
       " '2020-09-18',\n",
       " '2020-09-21',\n",
       " '2020-09-22']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getWeekday('20200411', '20200922')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
