{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu May 18 22:58:12 2017\n",
    "\n",
    "@author: c0redumb\n",
    "\"\"\"\n",
    "\n",
    "# To make print working for Python2/3\n",
    "from __future__ import print_function\n",
    "\n",
    "# Use six to import urllib so it is working for Python2/3\n",
    "from six.moves import urllib\n",
    "# If you don't want to use six, please comment out the line above\n",
    "# and use the line below instead (for Python3 only).\n",
    "#import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "Starting on May 2017, Yahoo financial has terminated its service on\n",
    "the well used EOD data download without warning. This is confirmed\n",
    "by Yahoo employee in forum posts.\n",
    "\n",
    "Yahoo financial EOD data, however, still works on Yahoo financial pages.\n",
    "These download links uses a \"crumb\" for authentication with a cookie \"B\".\n",
    "This code is provided to obtain such matching cookie and crumb.\n",
    "'''\n",
    "\n",
    "# Build the cookie handler\n",
    "cookier = urllib.request.HTTPCookieProcessor()\n",
    "opener = urllib.request.build_opener(cookier)\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "# Cookie and corresponding crumb\n",
    "_cookie = None\n",
    "_crumb = None\n",
    "\n",
    "# Headers to fake a user agent\n",
    "_headers={\n",
    "\t'User-Agent': 'Mozilla/5.0 (X11; U; Linux i686) Gecko/20071127 Firefox/2.0.0.11'\n",
    "}\n",
    "\n",
    "def _get_cookie_crumb():\n",
    "\t'''\n",
    "\tThis function perform a query and extract the matching cookie and crumb.\n",
    "\t'''\n",
    "\n",
    "\t# Perform a Yahoo financial lookup on SP500\n",
    "\treq = urllib.request.Request('https://finance.yahoo.com/quote/^GSPC', headers=_headers)\n",
    "\tf = urllib.request.urlopen(req)\n",
    "\talines = f.read().decode('utf-8')\n",
    "\n",
    "\t# Extract the crumb from the response\n",
    "\tglobal _crumb\n",
    "\tcs = alines.find('CrumbStore')\n",
    "\tcr = alines.find('crumb', cs + 10)\n",
    "\tcl = alines.find(':', cr + 5)\n",
    "\tq1 = alines.find('\"', cl + 1)\n",
    "\tq2 = alines.find('\"', q1 + 1)\n",
    "\tcrumb = alines[q1 + 1:q2]\n",
    "\t_crumb = crumb\n",
    "\n",
    "\t# Extract the cookie from cookiejar\n",
    "\tglobal cookier, _cookie\n",
    "\tfor c in cookier.cookiejar:\n",
    "\t\tif c.domain != '.yahoo.com':\n",
    "\t\t\tcontinue\n",
    "\t\tif c.name != 'B':\n",
    "\t\t\tcontinue\n",
    "\t\t_cookie = c.value\n",
    "\n",
    "\t# Print the cookie and crumb\n",
    "\t#print('Cookie:', _cookie)\n",
    "\t#print('Crumb:', _crumb)\n",
    "\n",
    "def load_yahoo_quote(ticker, begindate, enddate, info = 'quote', format_output = 'list'):\n",
    "\t'''\n",
    "\tThis function load the corresponding history/divident/split from Yahoo.\n",
    "\t'''\n",
    "\t# Check to make sure that the cookie and crumb has been loaded\n",
    "\tglobal _cookie, _crumb\n",
    "\tif _cookie == None or _crumb == None:\n",
    "\t\t_get_cookie_crumb()\n",
    "\n",
    "\t# Prepare the parameters and the URL\n",
    "\ttb = time.mktime((int(begindate[0:4]), int(begindate[4:6]), int(begindate[6:8]), 4, 0, 0, 0, 0, 0))\n",
    "\tte = time.mktime((int(enddate[0:4]), int(enddate[4:6]), int(enddate[6:8]), 18, 0, 0, 0, 0, 0))\n",
    "\n",
    "\tparam = dict()\n",
    "\tparam['period1'] = int(tb)\n",
    "\tparam['period2'] = int(te)\n",
    "\tparam['interval'] = '1d'\n",
    "\tif info == 'quote':\n",
    "\t\tparam['events'] = 'history'\n",
    "\telif info == 'dividend':\n",
    "\t\tparam['events'] = 'div'\n",
    "\telif info == 'split':\n",
    "\t\tparam['events'] = 'split'\n",
    "\tparam['crumb'] = _crumb\n",
    "\tparams = urllib.parse.urlencode(param)\n",
    "\turl = 'https://query1.finance.yahoo.com/v7/finance/download/{}?{}'.format(ticker, params)\n",
    "\t#print(url)\n",
    "\treq = urllib.request.Request(url, headers=_headers)\n",
    "\n",
    "\t# Perform the query\n",
    "\t# There is no need to enter the cookie here, as it is automatically handled by opener\n",
    "\tf = urllib.request.urlopen(req)\n",
    "\talines = f.read().decode('utf-8')\n",
    "\t#print(alines)\n",
    "\tif format_output == 'list':\n",
    "\t\treturn alines.split('\\n')\n",
    "\n",
    "\tif format_output == 'dataframe':\n",
    "\t\tnested_alines = [line.split(',') for line in alines[1:]]\n",
    "\t\tcols = alines[0].split(',')\n",
    "\t\tadf = pd.DataFrame.from_records(nested_alines, columns=cols)\n",
    "\t\treturn adf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
