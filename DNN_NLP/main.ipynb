{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python3\n",
    "import os\n",
    "\n",
    "import argparse\n",
    "import datetime\n",
    "import torch\n",
    "import model\n",
    "import numpy as np\n",
    "\n",
    "import util\n",
    "import json\n",
    "\n",
    "# import nltk\n",
    "# nltk.download()\n",
    "\n",
    "\n",
    "# credit to: https://github.com/Shawn1993/cnn-text-classification-pytorch/blob/master/main.py\n",
    "\n",
    "parser = argparse.ArgumentParser(description='CNN-based Financial News Classifier')\n",
    "# learning\n",
    "parser.add_argument('-lr', type=float, default=0.001, help='initial learning rate [default: 0.001]')\n",
    "parser.add_argument('-t', type=float, default=1, help='SGLD tempreture [default: 1]')\n",
    "\n",
    "parser.add_argument('-epochs', type=int, default=100, help='number of epochs for train [default: 100]')\n",
    "parser.add_argument('-batch-size', type=int, default=64, help='batch size for training [default: 64]')\n",
    "parser.add_argument('-save_dir', type=str, default='./input/models/', help='save thinning models')\n",
    "# model\n",
    "parser.add_argument('-dropout', type=float, default=0.5, help='the probability for dropout [default: 0.5]')\n",
    "parser.add_argument('-embed-dim', type=int, default=128, help='number of embedding dimension [default: 128]')\n",
    "parser.add_argument('-kernel-num', type=int, default=64, help='number of each kind of kernel')\n",
    "parser.add_argument('-kernel-sizes', type=str, default='2,3,4,5', help='comma-separated kernel size to use for convolution')\n",
    "parser.add_argument('-static', type=bool, default=True, help='fix the embedding')\n",
    "# device\n",
    "parser.add_argument('-device', type=int, default=-1, help='device to use for iterate data, -1 mean cpu [default: -1]')\n",
    "parser.add_argument('-no-cuda', action='store_true', default=False, help='disable the gpu')\n",
    "# option\n",
    "parser.add_argument('-predict', type=str, default=None, help='predict the sentence given')\n",
    "parser.add_argument('-eval', type=bool, default=False, help='evaluate testing set')\n",
    "parser.add_argument('-vocabs', type=int, default=6000, help='total number of vocabularies [default: 6000]')\n",
    "parser.add_argument('-words', type=int, default=40, help='max number of words in a sentence [default: 40]')\n",
    "parser.add_argument('-date', type=str, default='', help='date to be tested')\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "# load tokenized features\n",
    "data = np.genfromtxt('./input/featureMatrix_train')\n",
    "test = np.genfromtxt('./input/featureMatrix_test')\n",
    "np.random.shuffle(data)\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "label = util.value2int_simple(y).astype(\"int\") # using direction to label\n",
    "#label = to_categorical(value2int(y, clusters)).astype(\"int\") # using quantile to label\n",
    "validation_ratio = 0.05\n",
    "X = X.astype('float32')\n",
    "D = int(data.shape[0] * validation_ratio)  # total number of validation data\n",
    "X_train, y_train, X_valid, y_valid = X[:-D], label[:-D], X[-D:], label[-D:]\n",
    "X_test, y_test = test[:, :-1], test[:, -1]\n",
    "\n",
    "#print(\"Positive News Ratio\", sum(y_test > 0) * 1. / (sum(y_test > 0) + sum(y_test < 0)))\n",
    "X_test = X_test.astype('float32')\n",
    "y_test = util.value2int_simple(y_test).astype(\"int\")\n",
    "\n",
    "\n",
    "# update args and print\n",
    "args.class_num = 2\n",
    "args.cuda = (not args.no_cuda) and torch.cuda.is_available(); del args.no_cuda\n",
    "args.kernel_sizes = [int(k) for k in args.kernel_sizes.split(',')]\n",
    "\n",
    "print(\"\\nParameters:\")\n",
    "for attr, value in sorted(args.__dict__.items()):\n",
    "    print(\"\\t{}={}\".format(attr.upper(), value))\n",
    "\n",
    "\n",
    "# model\n",
    "cnn = model.CNN_Text(args)\n",
    "if args.cuda:\n",
    "    torch.cuda.set_device(args.device)\n",
    "    cnn = cnn.cuda()\n",
    "\n",
    "# train or predict\n",
    "if args.predict is not None:\n",
    "    if args.date != '':\n",
    "        print(util.daily_predict(cnn, args))\n",
    "        output = './input/news/' + args.date[:4] + '/news_' + args.date + '.csv'\n",
    "        os.system('mv ' + output + '_bak ' + output)\n",
    "\n",
    "    else:\n",
    "        mymodels, word2idx, stopWords = util.predictor_preprocess(cnn, args)\n",
    "        # util.bma_eval(X_test, y_test, mymodels, 'Testing   ', args)\n",
    "        print(util.predict(args.predict, mymodels, word2idx, stopWords, args))\n",
    "elif args.eval is not False:\n",
    "    mymodels, word2idx, stopWords = util.predictor_preprocess(cnn, args)\n",
    "    util.bma_eval(X_test, y_test, mymodels, 'Testing   ', args)\n",
    "else:\n",
    "    print()\n",
    "    try:\n",
    "        util.train(X_train, y_train, X_valid, y_valid, X_test, y_test, cnn, args)\n",
    "    except KeyboardInterrupt:\n",
    "        print('\\n' + '-' * 89)\n",
    "        print('Exiting from training early')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
