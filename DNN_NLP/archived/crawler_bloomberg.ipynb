{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import re\n",
    "import urllib2\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "'''\n",
    "Other useful crawler can be found in \n",
    "\n",
    "How to install scrapy\n",
    "https://doc.scrapy.org/en/latest/intro/install.html\n",
    "http://askubuntu.com/questions/675876/cant-install-some-packages-depends-x-but-x-is-to-be-installed\n",
    "'''\n",
    "\n",
    "class news_Bloomberg:\n",
    "    def __init__(self):\n",
    "        fin = open('./input/tickerList.csv')\n",
    "        # exit if the output already existed\n",
    "        if os.path.isfile('./input/news_bloomberg.csv'):\n",
    "            sys.exit(\"Bloomberg news already existed!\")\n",
    "        \n",
    "        filterList = set()\n",
    "        try:\n",
    "            fList = open('./input/finished.list')\n",
    "            for l in fList:\n",
    "                filterList.add(l.strip())\n",
    "        except: pass\n",
    "        \n",
    "        for line in fin:\n",
    "            line = line.strip().split(',')\n",
    "            ticker, name, exchange, MarketCap = line\n",
    "            if ticker in filterList: continue\n",
    "            print ticker\n",
    "            self.content(ticker, line)\n",
    "\n",
    "    def content(self, ticker, line):\n",
    "        url = \"http://www.bloomberg.com/search?sort=time:desc&query=\" + ticker \n",
    "        for pn in range(1, 500):\n",
    "            print(line, pn)\n",
    "            tag = self.repeatDownload(ticker, line, url, pn) # if page has news, tag 1, otherwise tag 0\n",
    "            if not tag: break\n",
    "\n",
    "    def repeatDownload(self, ticker, line, url, pn): \n",
    "        repeat_times = 4 # repeat downloading in case of http error\n",
    "        for _ in range(repeat_times): \n",
    "            try:\n",
    "                time.sleep(np.random.poisson(3))\n",
    "                response = urllib2.urlopen(url + \"&page=\" + str(pn))\n",
    "                data = response.read()\n",
    "                soup = BeautifulSoup(data, \"lxml\")\n",
    "                tag = self.parser(soup, line, ticker)\n",
    "                if not tag: return tag # if page has no news, return 0 to change ticker\n",
    "                break # skip loop if data fetched\n",
    "            except:\n",
    "                continue\n",
    "        return 1\n",
    "\n",
    "    def parser(self, soup, line, ticker):\n",
    "        timeSet = soup.find_all(\"div\", class_=\"search-result-story__metadata\")\n",
    "        titles = soup.find_all(\"h1\", class_=\"search-result-story__headline\")\n",
    "        tags = soup.find_all(\"div\", class_=\"search-result-story__body\")\n",
    "        fout = open('./input/news_bloomberg.csv', 'a+')\n",
    "        if len(timeSet) == 0: return 0\n",
    "        for i in range(len(timeSet)):    \n",
    "            timestamp = self.timeConvert(timeSet[i].time.get_text())\n",
    "            title = \" \".join(re.findall(r\"\\w+\", titles[i].a.get_text()))\n",
    "            abstract = \" \".join(re.findall(r\"\\w+\", tags[i].get_text()))\n",
    "            fout.write(','.join([ticker, line[1],timestamp, title, abstract]) + '\\n')\n",
    "        fout.close()\n",
    "        return 1\n",
    "\n",
    "    def timeConvert(self, time):\n",
    "        conv = {'Jan': '01', 'Feb': '02', 'Mar': '03', 'Apr': '04', \\\n",
    "                'May': '05', 'Jun': '06', 'Jul': '07', 'Aug': '08', \\\n",
    "                'Sep': '09', 'Oct': '10', 'Nov': '11', 'Dec': '12'}\n",
    "        timeFmt = ' '.join(re.findall(r\"\\w+\", time)) # format Nov 22 2016\n",
    "        periods = timeFmt.split(\" \")\n",
    "        if len(periods[1]) == 1: periods[1] = '0' + periods[1]\n",
    "        newTime = ''.join([periods[2], conv[periods[0]], periods[1]]) # format 20161122\n",
    "        return newTime\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def main():\n",
    "    news_Bloomberg()\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
