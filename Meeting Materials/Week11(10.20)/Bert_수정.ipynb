{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Bert_YGSentiment.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNndhrOwyBN5"
      },
      "source": [
        "import pandas as pd\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_d-wOcVy4-E",
        "outputId": "df41d412-7b76-407d-b30b-c9715270a34b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkUEsNpoXFwT",
        "outputId": "0af0499b-edb8-4599-9f61-dbe1bb1d5c10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        }
      },
      "source": [
        "data_m=pd.read_csv('/content/drive/My Drive/test_국제 (2).csv', encoding='utf-8-sig')\n",
        "data_m=data_m[['date','title','label_rev' ]]\n",
        "data_m"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>label_rev</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001.09.11</td>\n",
              "      <td>[美 '피의 화요일'] '세계무역센터 어떤 곳인가'</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001.09.11</td>\n",
              "      <td>[美 무역센터빌딩 폭발 이모저모] 미국주요도시 동시다발 테러공격</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001.09.11</td>\n",
              "      <td>뉴욕 세계무역센터 빌딩 비행기 충돌</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001.09.11</td>\n",
              "      <td>럼즈펠드 美 국방, 관료주의와의 전면전 선언</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2001.09.11</td>\n",
              "      <td>짧고 쉽게 답변...자신감 보여줘야 .. '성공취업인터뷰 요령'</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9367</th>\n",
              "      <td>2003.04.06</td>\n",
              "      <td>어린이건강보험 출시 .. 대한생명</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9368</th>\n",
              "      <td>2003.04.06</td>\n",
              "      <td>동화기업, 강화마루 판매 10만평 달성</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9369</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9370</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9371</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9372 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            date                                title  label_rev\n",
              "0     2001.09.11         [美 '피의 화요일'] '세계무역센터 어떤 곳인가'        0.0\n",
              "1     2001.09.11  [美 무역센터빌딩 폭발 이모저모] 미국주요도시 동시다발 테러공격        0.0\n",
              "2     2001.09.11                  뉴욕 세계무역센터 빌딩 비행기 충돌        0.0\n",
              "3     2001.09.11             럼즈펠드 美 국방, 관료주의와의 전면전 선언        0.0\n",
              "4     2001.09.11  짧고 쉽게 답변...자신감 보여줘야 .. '성공취업인터뷰 요령'        2.0\n",
              "...          ...                                  ...        ...\n",
              "9367  2003.04.06                   어린이건강보험 출시 .. 대한생명        1.0\n",
              "9368  2003.04.06                동화기업, 강화마루 판매 10만평 달성        1.0\n",
              "9369         NaN                                  NaN        NaN\n",
              "9370         NaN                                  NaN        NaN\n",
              "9371         NaN                                  NaN        NaN\n",
              "\n",
              "[9372 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIFUzlHhXHOK"
      },
      "source": [
        "indexNames_0 = data_m[ (data_m['label_rev'] == 0)].index\n",
        "indexNames_1 = data_m[ (data_m['label_rev'] == 1)].index"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddWaWi4XXHmo"
      },
      "source": [
        "neg=data_m.iloc[indexNames_0,:]\n",
        "pos=data_m.iloc[indexNames_1,:]"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esBxXlNrXIx5",
        "outputId": "ff924d6f-7278-43a3-e8d5-344ef2573e59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        }
      },
      "source": [
        "pos"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>label_rev</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>634</th>\n",
              "      <td>2008.10.29</td>\n",
              "      <td>노년ㆍ젊은부부 '바람기' 세졌다...의학.통신 발달로 외도 늘어</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>635</th>\n",
              "      <td>2008.10.29</td>\n",
              "      <td>시리아 , 美재침공 방지 촉구</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>636</th>\n",
              "      <td>2008.10.29</td>\n",
              "      <td>미국인 10명중 7명 \"오바마가 승리\"</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>637</th>\n",
              "      <td>2008.10.29</td>\n",
              "      <td>필리핀에 간 潘총장</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>638</th>\n",
              "      <td>2008.10.29</td>\n",
              "      <td>[고개 드는 증시 낙관론] 블랙스톤 슈워츠먼 회장 \"지금이 돈 벌수 있는 최적기\"</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9364</th>\n",
              "      <td>2003.04.06</td>\n",
              "      <td>빔 뒤젠베르 ECB총재, 임기연장 수락</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9365</th>\n",
              "      <td>2003.04.06</td>\n",
              "      <td>[헬로! 이코노미] '감사의견' .. 기업 재무제표 적정성여부 표시</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9366</th>\n",
              "      <td>2003.04.06</td>\n",
              "      <td>삼성애니카 운전자 상해보험 판매..레저활동 사고까지 보상</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9367</th>\n",
              "      <td>2003.04.06</td>\n",
              "      <td>어린이건강보험 출시 .. 대한생명</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9368</th>\n",
              "      <td>2003.04.06</td>\n",
              "      <td>동화기업, 강화마루 판매 10만평 달성</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4229 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            date                                          title  label_rev\n",
              "634   2008.10.29            노년ㆍ젊은부부 '바람기' 세졌다...의학.통신 발달로 외도 늘어        1.0\n",
              "635   2008.10.29                               시리아 , 美재침공 방지 촉구        1.0\n",
              "636   2008.10.29                          미국인 10명중 7명 \"오바마가 승리\"        1.0\n",
              "637   2008.10.29                                     필리핀에 간 潘총장        1.0\n",
              "638   2008.10.29  [고개 드는 증시 낙관론] 블랙스톤 슈워츠먼 회장 \"지금이 돈 벌수 있는 최적기\"        1.0\n",
              "...          ...                                            ...        ...\n",
              "9364  2003.04.06                          빔 뒤젠베르 ECB총재, 임기연장 수락        1.0\n",
              "9365  2003.04.06          [헬로! 이코노미] '감사의견' .. 기업 재무제표 적정성여부 표시        1.0\n",
              "9366  2003.04.06                삼성애니카 운전자 상해보험 판매..레저활동 사고까지 보상        1.0\n",
              "9367  2003.04.06                             어린이건강보험 출시 .. 대한생명        1.0\n",
              "9368  2003.04.06                          동화기업, 강화마루 판매 10만평 달성        1.0\n",
              "\n",
              "[4229 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9NbF0gHXKBp",
        "outputId": "3b3a64a6-24d7-4305-fa51-919fcde414bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        }
      },
      "source": [
        "neg"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>label_rev</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001.09.11</td>\n",
              "      <td>[美 '피의 화요일'] '세계무역센터 어떤 곳인가'</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001.09.11</td>\n",
              "      <td>[美 무역센터빌딩 폭발 이모저모] 미국주요도시 동시다발 테러공격</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001.09.11</td>\n",
              "      <td>뉴욕 세계무역센터 빌딩 비행기 충돌</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001.09.11</td>\n",
              "      <td>럼즈펠드 美 국방, 관료주의와의 전면전 선언</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2008.10.23</td>\n",
              "      <td>英공교육 성공신화 '호브파크 스쿨'</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4935</th>\n",
              "      <td>1998.11.09</td>\n",
              "      <td>공무원 업무수행때 정치적 요구에 민감 .. 전경련 조사</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4936</th>\n",
              "      <td>1998.11.09</td>\n",
              "      <td>[IMF를 '이긴 기업들'] (1) 'LG정보통신'..인터뷰 : 서평원</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4937</th>\n",
              "      <td>1998.11.09</td>\n",
              "      <td>빅딜대상중 사업성없는 업종.기업 \"퇴출\"...사업구조조정위</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5058</th>\n",
              "      <td>2020.03.23</td>\n",
              "      <td>자이, 고품격 아파트 지향…신규 분양 실시간 알림 추진</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5060</th>\n",
              "      <td>2020.03.23</td>\n",
              "      <td>프라우드, 땅 속 김장독처럼 야채·과일 신선하게 유지</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3388 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            date                                    title  label_rev\n",
              "0     2001.09.11             [美 '피의 화요일'] '세계무역센터 어떤 곳인가'        0.0\n",
              "1     2001.09.11      [美 무역센터빌딩 폭발 이모저모] 미국주요도시 동시다발 테러공격        0.0\n",
              "2     2001.09.11                      뉴욕 세계무역센터 빌딩 비행기 충돌        0.0\n",
              "3     2001.09.11                 럼즈펠드 美 국방, 관료주의와의 전면전 선언        0.0\n",
              "6     2008.10.23                      英공교육 성공신화 '호브파크 스쿨'        0.0\n",
              "...          ...                                      ...        ...\n",
              "4935  1998.11.09           공무원 업무수행때 정치적 요구에 민감 .. 전경련 조사        0.0\n",
              "4936  1998.11.09  [IMF를 '이긴 기업들'] (1) 'LG정보통신'..인터뷰 : 서평원        0.0\n",
              "4937  1998.11.09         빅딜대상중 사업성없는 업종.기업 \"퇴출\"...사업구조조정위        0.0\n",
              "5058  2020.03.23           자이, 고품격 아파트 지향…신규 분양 실시간 알림 추진        0.0\n",
              "5060  2020.03.23            프라우드, 땅 속 김장독처럼 야채·과일 신선하게 유지        0.0\n",
              "\n",
              "[3388 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRsXoS4iXNmH"
      },
      "source": [
        "\n",
        "# 나중에 SMOTE를 이용해서 neg 를 뻥튀기 해서 시험 해야함 "
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcRj17GHXQfF"
      },
      "source": [
        "neg=neg.iloc[0:3386,:]\n",
        "pos=pos.iloc[0:3386,:]"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q5UjaalXRx4",
        "outputId": "7e05cd3a-dfb7-4869-ff31-318378758c85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(len(pos))\n",
        "print(len(neg))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3386\n",
            "3386\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P1RwCOWyBN9"
      },
      "source": [
        "# neg = pd.read_csv('/content/drive/My Drive/Data_0.csv', encoding='CP949').dropna()\n",
        "# pos = pd.read_csv('/content/drive/My Drive/Data_1.csv', encoding='CP949').dropna()"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNKNKOxxyBOG"
      },
      "source": [
        "# pos = pos.loc[:, ['date','sen','라벨']]\n",
        "# pos"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NafO2NiJyBOQ",
        "outputId": "8ce8a460-04ab-4beb-eff7-8266f78e82a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        }
      },
      "source": [
        "pos['label_rev'] = 1\n",
        "neg['label_rev'] = 0\n",
        "# pos\n",
        "# neg\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>label_rev</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001.09.11</td>\n",
              "      <td>[美 '피의 화요일'] '세계무역센터 어떤 곳인가'</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001.09.11</td>\n",
              "      <td>[美 무역센터빌딩 폭발 이모저모] 미국주요도시 동시다발 테러공격</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001.09.11</td>\n",
              "      <td>뉴욕 세계무역센터 빌딩 비행기 충돌</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001.09.11</td>\n",
              "      <td>럼즈펠드 美 국방, 관료주의와의 전면전 선언</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2008.10.23</td>\n",
              "      <td>英공교육 성공신화 '호브파크 스쿨'</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4932</th>\n",
              "      <td>1998.11.09</td>\n",
              "      <td>[IMF를 '이긴 기업들'] (1) 'LG정보통신' .. 매출 2배 늘어</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4933</th>\n",
              "      <td>1998.11.09</td>\n",
              "      <td>공산품/가공식품 결함 10년까지 배상 의무화 .. 재정경제부</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4935</th>\n",
              "      <td>1998.11.09</td>\n",
              "      <td>공무원 업무수행때 정치적 요구에 민감 .. 전경련 조사</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4936</th>\n",
              "      <td>1998.11.09</td>\n",
              "      <td>[IMF를 '이긴 기업들'] (1) 'LG정보통신'..인터뷰 : 서평원</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4937</th>\n",
              "      <td>1998.11.09</td>\n",
              "      <td>빅딜대상중 사업성없는 업종.기업 \"퇴출\"...사업구조조정위</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3386 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            date                                     title  label_rev\n",
              "0     2001.09.11              [美 '피의 화요일'] '세계무역센터 어떤 곳인가'          0\n",
              "1     2001.09.11       [美 무역센터빌딩 폭발 이모저모] 미국주요도시 동시다발 테러공격          0\n",
              "2     2001.09.11                       뉴욕 세계무역센터 빌딩 비행기 충돌          0\n",
              "3     2001.09.11                  럼즈펠드 美 국방, 관료주의와의 전면전 선언          0\n",
              "6     2008.10.23                       英공교육 성공신화 '호브파크 스쿨'          0\n",
              "...          ...                                       ...        ...\n",
              "4932  1998.11.09  [IMF를 '이긴 기업들'] (1) 'LG정보통신' .. 매출 2배 늘어          0\n",
              "4933  1998.11.09         공산품/가공식품 결함 10년까지 배상 의무화 .. 재정경제부          0\n",
              "4935  1998.11.09            공무원 업무수행때 정치적 요구에 민감 .. 전경련 조사          0\n",
              "4936  1998.11.09   [IMF를 '이긴 기업들'] (1) 'LG정보통신'..인터뷰 : 서평원          0\n",
              "4937  1998.11.09          빅딜대상중 사업성없는 업종.기업 \"퇴출\"...사업구조조정위          0\n",
              "\n",
              "[3386 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8HTgFeCyBOT"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoJI2LlqyBOW"
      },
      "source": [
        "pos_train, pos_test = train_test_split(pos, test_size=0.3, shuffle=True, random_state=1004)\n",
        "neg_train, neg_test = train_test_split(neg, test_size=0.3, shuffle=True, random_state=1004)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P1hun9gyBOY",
        "outputId": "dc6bcebd-5f60-4c48-a8a6-e6721a0244f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "print(len(pos_train)/len(pos)*100)\n",
        "print(len(pos_test)/len(pos)*100)\n",
        "print(len(neg_train)/len(neg)*100)\n",
        "print(len(neg_test)/len(neg)*100)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "69.99409332545777\n",
            "30.00590667454223\n",
            "69.99409332545777\n",
            "30.00590667454223\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5-LjS1syBOd"
      },
      "source": [
        "# # Smote를 사용해본다\n",
        "# from imblearn.over_sampling import SMOTE\n",
        "# smote = SMOTE(random_state=0)\n",
        "# pos_train_over,neg_train_over = smote.fit_sample(pos_train,neg_train)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDIXk5ZzyBOf",
        "outputId": "2f93fd03-69c4-4d79-df9f-e32549c4d72b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "train = pd.concat([pos_train, neg_train])\n",
        "test = pd.concat([pos_test, neg_test])\n",
        "print(len(train))\n",
        "print(len(test))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4740\n",
            "2032\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi0T8tzTyBOh"
      },
      "source": [
        "train_df = train.sample(frac=0.4, random_state=999)\n",
        "test_df = test.sample(frac=0.4, random_state=999)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7gzYY5X1v7q"
      },
      "source": [
        "train_df=train_df[['date','title','label_rev']]\n",
        "test_df=test_df[['date','title','label_rev']]"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyIINsi7yBOl",
        "outputId": "aee8929e-034e-45ef-e2b3-8772a13e3eba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        }
      },
      "source": [
        "train_df.columns = ['date','title','label_rev']\n",
        "test_df.columns = ['date','title','label_rev']\n",
        "test_df"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>label_rev</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6369</th>\n",
              "      <td>1998.10.14</td>\n",
              "      <td>[금융/정치면톱] '내년 출범 금융감독원 조직 잠정 결정'</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1083</th>\n",
              "      <td>2000.05.30</td>\n",
              "      <td>미쓰비시와 히타치 청강부문 통합모색</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1093</th>\n",
              "      <td>2008.11.20</td>\n",
              "      <td>오바마 내각 '3색 코드'로 간다</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6426</th>\n",
              "      <td>1998.10.14</td>\n",
              "      <td>[뉴스파일] 소액예금 이자세 감면 시한 2년 연장 추진</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2958</th>\n",
              "      <td>2011.08.18</td>\n",
              "      <td>백용호 \"中企 상속세 독일처럼 대폭 경감\"</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8222</th>\n",
              "      <td>2008.10.27</td>\n",
              "      <td>예금금리 다음주부터 인하</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6088</th>\n",
              "      <td>1997.12.25</td>\n",
              "      <td>대명금속, '함인동볼' 국내 첫 개발 .. PCB도금 소재</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237</th>\n",
              "      <td>1997.10.27</td>\n",
              "      <td>[서치라이트] 일본 자동차용 자동항법장치 SW '큰 인기'</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7809</th>\n",
              "      <td>2008.11.20</td>\n",
              "      <td>원자재가격 급락…유가 50弗 붕괴</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6672</th>\n",
              "      <td>1998.09.23</td>\n",
              "      <td>'벤처기업 마케팅전략' 세미나 개최 .. 주제발표 내용요약</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>813 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            date                             title  label_rev\n",
              "6369  1998.10.14  [금융/정치면톱] '내년 출범 금융감독원 조직 잠정 결정'          1\n",
              "1083  2000.05.30               미쓰비시와 히타치 청강부문 통합모색          1\n",
              "1093  2008.11.20                오바마 내각 '3색 코드'로 간다          1\n",
              "6426  1998.10.14    [뉴스파일] 소액예금 이자세 감면 시한 2년 연장 추진          1\n",
              "2958  2011.08.18           백용호 \"中企 상속세 독일처럼 대폭 경감\"          0\n",
              "...          ...                               ...        ...\n",
              "8222  2008.10.27                     예금금리 다음주부터 인하          1\n",
              "6088  1997.12.25  대명금속, '함인동볼' 국내 첫 개발 .. PCB도금 소재          1\n",
              "237   1997.10.27  [서치라이트] 일본 자동차용 자동항법장치 SW '큰 인기'          0\n",
              "7809  2008.11.20                원자재가격 급락…유가 50弗 붕괴          1\n",
              "6672  1998.09.23  '벤처기업 마케팅전략' 세미나 개최 .. 주제발표 내용요약          1\n",
              "\n",
              "[813 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc9mjTBD2JLv",
        "outputId": "6878ec1c-7e3e-49b4-e731-df150e2253de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        }
      },
      "source": [
        "!pip install pytorch_transformers"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_transformers in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (0.1.91)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (0.0.43)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (2.20.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.16.0)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.6.0+cu101)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (1.11.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (0.16.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (2.7)\n",
            "Collecting botocore<1.20.0,>=1.19.0\n",
            "  Using cached https://files.pythonhosted.org/packages/7a/38/317bec1175e74b817a51ca806f3e5822f340bb3b344e8693425122499f4f/botocore-1.19.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_transformers) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_transformers) (0.3.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch_transformers) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.0->boto3->pytorch_transformers) (2.8.0)\n",
            "\u001b[31mERROR: botocore 1.19.0 has requirement urllib3<1.26,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: awsebcli 3.19.1 has requirement botocore<1.18,>=1.17, but you'll have botocore 1.19.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: awsebcli 3.19.1 has requirement PyYAML<5.4,>=5.3.1, but you'll have pyyaml 3.13 which is incompatible.\u001b[0m\n",
            "Installing collected packages: botocore\n",
            "  Found existing installation: botocore 1.18.18\n",
            "    Uninstalling botocore-1.18.18:\n",
            "      Successfully uninstalled botocore-1.18.18\n",
            "Successfully installed botocore-1.19.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "botocore"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oFylOw_VNk-",
        "outputId": "960aa97f-5ed9-43ed-94a4-50985c5ad67b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install awscli awsebcli botocore==1.18.18 --upgrade"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting awscli\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4d/bf/3beb2e763d0c5d7db634a76f71faf5a577e315606207b33fd3578fbe5a4b/awscli-1.18.160-py2.py3-none-any.whl (3.4MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4MB 4.5MB/s \n",
            "\u001b[?25hCollecting awsebcli\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/26/6e51c423dddda05204f36c927f079aa1972617c3cafcd4b434cd034e7cd1/awsebcli-3.19.1.tar.gz (249kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 40.8MB/s \n",
            "\u001b[?25hCollecting botocore==1.18.18\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/72/984ac8f33b5c8df5ff63f323a8724f65b4d0f8956968b942b77d35d3a1ef/botocore-1.18.18-py2.py3-none-any.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 34.0MB/s \n",
            "\u001b[?25hCollecting colorama<0.4.4,>=0.2.5; python_version != \"3.4\"\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: PyYAML<5.4,>=3.10; python_version != \"3.4\" in /usr/local/lib/python3.6/dist-packages (from awscli) (3.13)\n",
            "Collecting rsa<=4.5.0,>=3.1.2; python_version != \"3.4\"\n",
            "  Downloading https://files.pythonhosted.org/packages/26/f8/8127fdda0294f044121d20aac7785feb810e159098447967a6103dedfb96/rsa-4.5-py2.py3-none-any.whl\n",
            "Collecting docutils<0.16,>=0.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cd/a6aa959dca619918ccb55023b4cb151949c64d4d5d55b3f4ffd7eee0c6e8/docutils-0.15.2-py3-none-any.whl (547kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 57.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from awscli) (0.3.3)\n",
            "Collecting cement==2.8.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/60/608f0b8975f4ee7deaaaa7052210d095e0b96e7cd3becdeede9bd13674a1/cement-2.8.2.tar.gz (165kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 57.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: future<0.17.0,>=0.16.0 in /usr/local/lib/python3.6/dist-packages (from awsebcli) (0.16.0)\n",
            "Collecting pathspec==0.5.9\n",
            "  Downloading https://files.pythonhosted.org/packages/84/2a/bfee636b1e2f7d6e30dd74f49201ccfa5c3cf322d44929ecc6c137c486c5/pathspec-0.5.9.tar.gz\n",
            "Collecting python-dateutil<2.8.1,>=2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 55.0MB/s \n",
            "\u001b[?25hCollecting requests<2.21,>=2.20.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/17/5cbb026005115301a8fb2f9b0e3e8d32313142fe8b617070e7baad20554f/requests-2.20.1-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools>=20.0 in /usr/local/lib/python3.6/dist-packages (from awsebcli) (50.3.0)\n",
            "Collecting semantic_version==2.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bd/8d/49a968bafda84c2f1c39a9ed429e37cb75cc03896e8d6b873001e6456fad/semantic_version-2.5.0-py3-none-any.whl\n",
            "Collecting six<1.12.0,>=1.11.0\n",
            "  Downloading https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: termcolor==1.1.0 in /usr/local/lib/python3.6/dist-packages (from awsebcli) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.24.1 in /usr/local/lib/python3.6/dist-packages (from awsebcli) (1.24.3)\n",
            "Collecting wcwidth<0.2.0,>=0.1.7\n",
            "  Downloading https://files.pythonhosted.org/packages/f6/d5/1ecdac957e3ea12c1b319fcdee8b6917ffaff8b4644d673c4d72d2f20b49/wcwidth-0.1.9-py2.py3-none-any.whl\n",
            "Collecting docker-compose<1.26.0,>=1.25.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/35/1dfbb8e6b2ce5d290622a49cae0a7f3cf09cdc4341380a600aee00530881/docker_compose-1.25.5-py2.py3-none-any.whl (139kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 54.6MB/s \n",
            "\u001b[?25hCollecting blessed>=1.9.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/37/241fec1c8fa767b445c5afb5cfa7eb78cef07f85489b51c2cf292b530265/blessed-1.17.11-py2.py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from botocore==1.18.18) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<=4.5.0,>=3.1.2; python_version != \"3.4\"->awscli) (0.4.8)\n",
            "Collecting idna<2.8,>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/2a/0276479a4b3caeb8a8c1af2f8e4355746a97fab05a372e4a2c6a6b876165/idna-2.7-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<2.21,>=2.20.1->awsebcli) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<2.21,>=2.20.1->awsebcli) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: docopt<1,>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from docker-compose<1.26.0,>=1.25.2->awsebcli) (0.6.2)\n",
            "Collecting dockerpty<1,>=0.4.1\n",
            "  Downloading https://files.pythonhosted.org/packages/8d/ee/e9ecce4c32204a6738e0a5d5883d3413794d7498fe8b06f44becc028d3ba/dockerpty-0.4.1.tar.gz\n",
            "Collecting texttable<2,>=0.9.0\n",
            "  Downloading https://files.pythonhosted.org/packages/06/f5/46201c428aebe0eecfa83df66bf3e6caa29659dbac5a56ddfd83cae0d4a4/texttable-1.6.3-py2.py3-none-any.whl\n",
            "Collecting cached-property<2,>=1.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/48/19/f2090f7dad41e225c7f2326e4cfe6fff49e57dedb5b53636c9551f86b069/cached_property-1.5.2-py2.py3-none-any.whl\n",
            "Collecting docker[ssh]<5,>=3.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/8c/8d42dbd83679483db207535f4fb02dc84325fa78b290f057694b057fcd21/docker-4.3.1-py2.py3-none-any.whl (145kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 53.3MB/s \n",
            "\u001b[?25hCollecting websocket-client<1,>=0.32.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 52.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: jsonschema<4,>=2.5.1 in /usr/local/lib/python3.6/dist-packages (from docker-compose<1.26.0,>=1.25.2->awsebcli) (2.6.0)\n",
            "Collecting paramiko>=2.4.2; extra == \"ssh\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/19/124e9287b43e6ff3ebb9cdea3e5e8e88475a873c05ccdf8b7e20d2c4201e/paramiko-2.7.2-py2.py3-none-any.whl (206kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 49.7MB/s \n",
            "\u001b[?25hCollecting bcrypt>=3.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/70/6d218afbe4c73538053c1016dd631e8f25fffc10cd01f5c272d7acf3c03d/bcrypt-3.2.0-cp36-abi3-manylinux2010_x86_64.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.6MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/62/30f6936941d87a5ed72efb24249437824f6b2c953901245b58c91fde2f27/cryptography-3.1.1-cp35-abi3-manylinux2010_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 51.1MB/s \n",
            "\u001b[?25hCollecting pynacl>=1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/57/2f5e6226a674b2bcb6db531e8b383079b678df5b10cdaa610d6cf20d77ba/PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961kB)\n",
            "\u001b[K     |████████████████████████████████| 962kB 53.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: cffi>=1.1 in /usr/local/lib/python3.6/dist-packages (from bcrypt>=3.1.3->paramiko>=2.4.2; extra == \"ssh\"->docker[ssh]<5,>=3.7.0->docker-compose<1.26.0,>=1.25.2->awsebcli) (1.14.3)\n",
            "Requirement already satisfied, skipping upgrade: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4.2; extra == \"ssh\"->docker[ssh]<5,>=3.7.0->docker-compose<1.26.0,>=1.25.2->awsebcli) (2.20)\n",
            "Building wheels for collected packages: awsebcli, cement, pathspec, dockerpty\n",
            "  Building wheel for awsebcli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for awsebcli: filename=awsebcli-3.19.1-cp36-none-any.whl size=357561 sha256=f19a213bdf6fd6eb5f769d03b044cde9f5b0f940695da56aaee345279a7231c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/8c/0c/0f27126aa6b5cd9d0ca7f8b7afe663b053accabb441ada7d30\n",
            "  Building wheel for cement (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cement: filename=cement-2.8.2-cp36-none-any.whl size=99714 sha256=52e54c041732d9e7ab2bbf46d836207c19e2fbabbff9fc73a3422878dbc20b15\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/9e/02/0af61a0ed625ea3decf29b8602fc0cbecc38943f19e076bb2e\n",
            "  Building wheel for pathspec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathspec: filename=pathspec-0.5.9-cp36-none-any.whl size=26357 sha256=b19b51532b55ae4836ae688aec69130b06c839d79b5ead2a857259aabbda1c8c\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/cb/7e/ce6e6062c69446e39e328170524ca8213498bc66a74c6a210b\n",
            "  Building wheel for dockerpty (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dockerpty: filename=dockerpty-0.4.1-cp36-none-any.whl size=16606 sha256=6eef88731e97f098490de809256e5b24dacea8456a7d016a58b58bfe8321a495\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/1e/86/bd0a97a0907c6c654af654d5875d1d4383dd1f575f77cee4aa\n",
            "Successfully built awsebcli cement pathspec dockerpty\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement six>=1.12.0, but you'll have six 1.11.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-hub 0.9.0 has requirement six>=1.12.0, but you'll have six 1.11.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorboard 2.3.0 has requirement requests<3,>=2.21.0, but you'll have requests 2.20.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: nbclient 0.5.0 has requirement jupyter-client>=6.1.5, but you'll have jupyter-client 5.3.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.20.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you'll have six 1.11.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: dm-tree 0.1.5 has requirement six>=1.12.0, but you'll have six 1.11.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: boto3 1.16.0 has requirement botocore<1.20.0,>=1.19.0, but you'll have botocore 1.18.18 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: awscli 1.18.160 has requirement botocore==1.19.0, but you'll have botocore 1.18.18 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: awsebcli 3.19.1 has requirement botocore<1.18,>=1.17, but you'll have botocore 1.18.18 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: awsebcli 3.19.1 has requirement PyYAML<5.4,>=5.3.1, but you'll have pyyaml 3.13 which is incompatible.\u001b[0m\n",
            "Installing collected packages: colorama, rsa, docutils, six, python-dateutil, botocore, awscli, cement, pathspec, idna, requests, semantic-version, wcwidth, dockerpty, texttable, cached-property, websocket-client, bcrypt, cryptography, pynacl, paramiko, docker, docker-compose, blessed, awsebcli\n",
            "  Found existing installation: rsa 4.6\n",
            "    Uninstalling rsa-4.6:\n",
            "      Successfully uninstalled rsa-4.6\n",
            "  Found existing installation: docutils 0.16\n",
            "    Uninstalling docutils-0.16:\n",
            "      Successfully uninstalled docutils-0.16\n",
            "  Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Found existing installation: python-dateutil 2.8.1\n",
            "    Uninstalling python-dateutil-2.8.1:\n",
            "      Successfully uninstalled python-dateutil-2.8.1\n",
            "  Found existing installation: botocore 1.19.0\n",
            "    Uninstalling botocore-1.19.0:\n",
            "      Successfully uninstalled botocore-1.19.0\n",
            "  Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: wcwidth 0.2.5\n",
            "    Uninstalling wcwidth-0.2.5:\n",
            "      Successfully uninstalled wcwidth-0.2.5\n",
            "Successfully installed awscli-1.18.160 awsebcli-3.19.1 bcrypt-3.2.0 blessed-1.17.11 botocore-1.18.18 cached-property-1.5.2 cement-2.8.2 colorama-0.4.3 cryptography-3.1.1 docker-4.3.1 docker-compose-1.25.5 dockerpty-0.4.1 docutils-0.15.2 idna-2.7 paramiko-2.7.2 pathspec-0.5.9 pynacl-1.4.0 python-dateutil-2.8.0 requests-2.20.1 rsa-4.5 semantic-version-2.5.0 six-1.11.0 texttable-1.6.3 wcwidth-0.1.9 websocket-client-0.57.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "botocore",
                  "dateutil",
                  "six",
                  "wcwidth"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS6tcGHqyBOn"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pytorch_transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZwO0aMXyBOq",
        "outputId": "9629c025-fc11-4986-af1d-52d42e84c5c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!git clone https://github.com/e9t/nsmc.git"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'nsmc' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52zTF3WJWKmn"
      },
      "source": [
        "class NsmcDataset(Dataset):\n",
        "    ''' Naver Sentiment Movie Corpus Dataset '''\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.df.iloc[idx, 1]\n",
        "        label = self.df.iloc[idx, 2]\n",
        "        return text, label"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EammALOEyBOt"
      },
      "source": [
        "nsmc_train_dataset = NsmcDataset(train_df)\n",
        "train_loader = DataLoader(nsmc_train_dataset, batch_size=2, shuffle=True, num_workers=2)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4agoxPOXyBOv",
        "outputId": "e70f1d29-1af9-4e06-9e16-d757c3916de1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased')\n",
        "model.to(device)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjrwzXPgyBOy",
        "outputId": "50e2beaf-ae37-4dbf-a8de-77bc5bd0179a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "optimizer = Adam(model.parameters(), lr=1e-6)\n",
        "\n",
        "itr = 3\n",
        "p_itr = 500\n",
        "epochs = 3\n",
        "total_loss = 0\n",
        "total_len = 0\n",
        "total_correct = 0\n",
        "\n",
        "\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    for text, label in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
        "        padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
        "        sample = torch.tensor(padded_list)\n",
        "        sample, label = sample.to(device), label.to(device)\n",
        "        labels = torch.tensor(label)\n",
        "        outputs = model(sample, labels=labels)\n",
        "        loss, logits = outputs\n",
        "\n",
        "        pred = torch.argmax(F.softmax(logits), dim=1)\n",
        "        correct = pred.eq(labels)\n",
        "        total_correct += correct.sum().item()\n",
        "        total_len += len(labels)\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if itr % p_itr == 0:\n",
        "            print('[Epoch {}/{}] Iteration {} -> Train Loss: {:.4f}, Accuracy: {:.3f}'.format(epoch+1, epochs, itr, total_loss/p_itr, total_correct/total_len))\n",
        "            total_loss = 0\n",
        "            total_len = 0\n",
        "            total_correct = 0\n",
        "\n",
        "        itr+=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fppvccguyBO0"
      },
      "source": [
        "# evaluation\n",
        "model.eval()\n",
        "\n",
        "nsmc_eval_dataset = NsmcDataset(test_df)\n",
        "eval_loader = DataLoader(nsmc_eval_dataset, batch_size=2, shuffle=False, num_workers=2)\n",
        "\n",
        "total_loss = 0\n",
        "total_len = 0\n",
        "total_correct = 0\n",
        "\n",
        "for text, label in eval_loader:\n",
        "    encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
        "    padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
        "    sample = torch.tensor(padded_list)\n",
        "    sample, label = sample.to(device), label.to(device)\n",
        "    labels = torch.tensor(label)\n",
        "    outputs = model(sample, labels=labels)\n",
        "    _, logits = outputs\n",
        "\n",
        "    pred = torch.argmax(F.softmax(logits), dim=1)\n",
        "    correct = pred.eq(labels)\n",
        "    total_correct += correct.sum().item()\n",
        "    total_len += len(labels)\n",
        "\n",
        "print('Test accuracy: ', total_correct / total_len)\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-Qi47IF4dD8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}